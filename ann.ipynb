{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpIGFMhHAro9MtCXVdTt0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderANYA/AI-Course/blob/main/ann.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6AAXTllrjMq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/digipodium/Datasets/main/classfication/bank_data.csv')\n",
        "df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T2lNf8uEsZoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "M01X2yD6smqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include='number').columns.tolist()\n",
        "num_cols.remove('Exited')\n",
        "cat_cols = df.select_dtypes(exclude='number').columns.tolist()\n",
        "num_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "cat_pipe = Pipeline([\n",
        "    ('encoder', OrdinalEncoder())\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols)\n",
        "])\n",
        "preprocessor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rAnN2zu-svFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']\n",
        "X = preprocessor.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jTklBAOrs33L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential ann**"
      ],
      "metadata": {
        "id": "ciQCLszLtLMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.__version__"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rxIWAj8Dtfpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wmYnujdQtyk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification nn model\n",
        "model =  tf.keras.models.Sequential()\n",
        "# 1st hidden layer (+ input layer)\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', input_dim=X_train.shape[1])\n",
        ")\n",
        "# 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "# output layer\n",
        "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "# sigmoid activation function for binary classification\n",
        "# softmax for multi-class classification\n",
        "# linear for regression\n",
        "\n",
        "# compile model\n",
        "model.compile(\n",
        "    optimizer='adam',        # gradient descent algorithm - Adam is the best\n",
        "    loss='binary_crossentropy',\n",
        ")\n",
        "# bimary_crossentropy for binary classification\n",
        "# categorical_crossentropy for multi-class classification\n",
        "# mean_squared_error for regression\n",
        "\n",
        "# summary\n",
        "model.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RpmpD3b-t2wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "epochs = 50\n",
        "batch_size = 8\n",
        "patience = 10\n",
        "\n",
        "# early stopping\n",
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=patience,\n",
        ")\n",
        "\n",
        "# train model\n",
        "history = model.fit(\n",
        "    X_train,                # feature matrix\n",
        "    y_train,                # target vector\n",
        "    validation_split=0.2,   # 20% data for validation\n",
        "    epochs=epochs,          # number of epochs\n",
        "    batch_size=batch_size,  # batch size\n",
        "    callbacks=[es],         # early stopping\n",
        "    verbose=1               # print output\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rLKe24nVt-Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize training history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train', marker='o', color='r')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3infVJciubXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XZXCbH1Auo8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "model.save('model_v1.h5') # creates a HDF5 file 'model_v1.h5'"
      ],
      "metadata": {
        "id": "zOpjjwWruuBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save weights to disk\n",
        "model.save_weights('model_weights_v1.h5') # creates a HDF5 file 'model_weights_v1.h5'"
      ],
      "metadata": {
        "id": "DRDwiB9lu2YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "model = tf.keras.models.load_model('model_v1.h5')"
      ],
      "metadata": {
        "id": "AiWvgofkvL5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\n",
        "# load weights from disk\n",
        "# declare the model as you did before\n",
        "# model =  tf.keras.models.Sequential()\n",
        "# model.add(...)\n",
        "# model.compile(...)\n",
        "# model.load_weights('model_weights_v1.h5')\n",
        "**"
      ],
      "metadata": {
        "id": "fA2N2oFjvnES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5) # convert probabilities to binary values\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "xoxp8wmOEj34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}